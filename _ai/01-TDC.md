---
title: "TensorFlow Developer Certificate"
layout: single
header:
  teaser: /assets/images/TDC.jpg
---

> Cousera에서 운영하는 "TensorFlow Developer Certificate" 과정의 학습강좌 및 텐서플로우 노트북 입니다.

## Class 1. AI, 머신러닝, 딥러닝
* W-1. 프로그래밍 패러다임
  1. 머신러닝 기초 ([Video][c1-w1-v1])
  2. 신경망의 ‘Hello World’ ([Video][c1-w1-v2])
  3. 텐서플로우 ‘Hello World’ 실습 ([Video][c1-w1-v3], [YouTube][c1-w1-y3], [Notebook][c1-w1-n3])
  4. 참고
    * 머신러닝의 'Hello World' ([Codelab][c1-w1-c4])
    * Ex-1: Housing Prices ([Exercise-1][c1-w1-e1])
* W-2. 컴퓨터 비전 
  1. 컴퓨터 비전 소개 ([Video][c1-w2-v1])
  2. 학습 데이터 로딩 코드 작성 ([Video][c1-w2-v2])
  3. 컴퓨터 비전 신경망 코딩 ([Video][c1-w2-v3], [YouTube][c1-w2-y3])
  4. 컴퓨터 비전 노트북  ([Video][c1-w2-v4], [Notebook][c1-w2-n4])
  5. 학습을 콘트롤하기 위한 Callback 사용 ([Video][c1-w2-v5])
  6. Callback으로 노트북 실습 ([Video][c1-w2-v6], [Notebook][c1-w2-n6])
  7. 참고
    * Computer Vision Model ([Codelab][c1-w2-c7])
* W-3. CNN으로 비전 향상
  1. Convolution과 pooling 이란? ([Video][c1-w3-v1])
  2. Convolutional layer 구현 ([Video][c1-w3-v2])
  3. Pooling layer 구현 ([Video][c1-w3-v3])
  4. 컨벌루션으로 Fashion classifier 성능향상 ([Video][c1-w3-v4])
  5. 컨벌루션 실습 ([Video][c1-w3-v5])
* W-4. 실생활 이미지 사용
  1. ImageGenerator 이해 ([Video][c1-w4-v1])
  2. 복잡한 이미지에 사용하기 위한 ConvNet 정의 ([Video][c1-w4-v2])
  3. fit_generator와 함께 ConvNet 학습 ([Video][c1-w4-v3])
  4. ConvNet 작업하기 ([Video][c1-w4-v4])
  5. fit_generator와 함께 ConvNet 학습 작업하기 ([Video][c1-w4-v5])
  6. 테스트 정확도에 대한 자동 검증 ([Video][c1-w4-v6])
  7. 이미지 압축 효과 탐색 ([Video][c1-w4-v7])

[c1-w1-v1]: https://drive.google.com/file/d/1Cf_9DH7KWcLz7YJ-W4DHGngaMrVE15pX/view?usp=sharing
[c1-w1-v2]: https://drive.google.com/file/d/1CemGe4AnOjuOm7OE4C5AycbLzrP-D565/view?usp=sharing
[c1-w1-v3]: https://drive.google.com/file/d/1CfQYOuy4BD6H_bPzh4eYMph-2dnyBQCC/view?usp=sharing
[c1-w1-y3]: https://youtu.be/inN8seMm7UI
[c1-w1-n3]: https://colab.research.google.com/drive/1Ks5xx0a9Pj1cqkOHQdEBCH7Lp19nFUIo
[c1-w1-c4]: https://developers.google.com/codelabs/tensorflow-1-helloworld
[c1-w1-e1]: https://colab.research.google.com/drive/1bOZcCbQE8OreI_mqY89z6RMpzXEvzkz8
[c1-w2-v1]: https://drive.google.com/file/d/1CjA1cS5tW3S4FeRniPYP_bnluFsgkLPr/view?usp=sharing
[c1-w2-v2]: https://drive.google.com/file/d/1CjOZJ9_wDl4Cs8LCyUZGjI8_I66LcQTD/view?usp=sharing
[c1-w2-v3]: https://drive.google.com/file/d/1Ckp6Mi7UYzXPtFHqLGADfjm9boM63Wm6/view?usp=sharing
[c1-w2-y3]: https://youtu.be/fXOsFF95ifk
[c1-w2-v4]: https://drive.google.com/file/d/1D8kuCDTflhbe3TX06v9IjRvmIILU4UxT/view?usp=sharing
[c1-w2-n4]: https://colab.research.google.com/drive/1GSianNRgCgUVUOxSYAS1t5dRZUg7E8dn
[c1-w2-v5]: https://drive.google.com/file/d/1D5anYmJtOjqyv4iYoYr75nwp1_dF5irT/view?usp=sharing
[c1-w2-v6]: https://drive.google.com/file/d/1D8ynv5icDFUqMdLKTJhkRBdO6LiQUlJa/view?usp=sharing
[c1-w2-n6]: https://colab.research.google.com/drive/1-Aoj3vcaOMxDOJR_1claWLqNq0aUXK6s
[c1-w2-c7]: https://developers.google.com/codelabs/tensorflow-lab2-computervision
[c1-w3-v1]: https://drive.google.com/file/d/1CuKl1wzhruxTi0txKKcfolhc_s8k-_9C/view?usp=sharing
[c1-w3-v2]: https://drive.google.com/file/d/1CuLuZOplS7ymwRL-8FDKSMRW2wRLxjo8/view?usp=sharing
[c1-w3-v3]: https://drive.google.com/file/d/1Cx05IMoAaYrIykTnFGf0mBrV3UmqeJyQ/view?usp=sharing
[c1-w3-v4]: https://drive.google.com/file/d/1D4AEbvno9QZ-2f8L0Udr_tpuB5drhuRG/view?usp=sharing
[c1-w3-v5]: https://drive.google.com/file/d/1D4CCpUEyZce86-4Pnp7KCRM4KDKkdfpK/view?usp=sharing
[c1-w4-v1]: https://drive.google.com/file/d/1D4eeg2v4tNM6k98-c3vftdxRBMX2uXof/view?usp=sharing
[c1-w4-v2]: https://drive.google.com/file/d/1DN1MiJfYsZZZr_bkzpdmBuXKEjGQw2x8/view?usp=sharing
[c1-w4-v3]: https://drive.google.com/file/d/1DMWJkNClTxRs9a4K93znl4T-MtS7U9mh/view?usp=sharing
[c1-w4-v4]: https://drive.google.com/file/d/1DNY8vdkzR0kCOh4g_UpFOw6opUu8lTfI/view?usp=sharing
[c1-w4-v5]: https://drive.google.com/file/d/1DK4M95npZV1azIU2VLp0jgKm44SG7KZp/view?usp=sharing
[c1-w4-n5]: https://
[c1-w4-v6]: https://drive.google.com/file/d/1DLc50ujPjCCLcPAgs83gOiVyRLlguC37/view?usp=sharing
[c1-w4-v7]: https://drive.google.com/file/d/1DL9M1xddEn6U5zqphRXrHfPpwA2pvmZI/view?usp=sharing


## Class 2. 턴서플로우에서 CNN
* W-1. 대규모 Dataset 사용
  1. 고양이와 개 dataset 학습 ([Video][c2-w1-v1])
  2. 노트북 실습 ([Video][c2-w1-v2], [Notebook][c2-w1-n2])
  3. Cropping ([Video][c2-w1-v3])
  4. 컨벌루션 효과 시각화 ([Video][c2-w1-v4])
  5. Accuracy와 loss 관점의 해석 ([Video][c2-w1-v5])
  6. 참고
    * [Kaggle data][c2-w1-kg]
    * Ex-2: Cats vs. Dogs ([Exercise-2][c2-w1-e2])
* W-2. Augmentation: overfitting을 피하는 방법
  1. Augmentation 서론 ([Video][c2-w2-v1])
  2. ImageDataGenerator로 augmentation 코딩 ([Video][c2-w2-v2])
  3. 고양이와 개 데이터에서 overfitting 데모 ([Video][c2-w2-v3])
  4. Adding augmentation to cats vs. dogs ([Video][c2-w2-v4])
  5. Exploring augmentation with horses vs. humans ([Video][c2-w2-v5])
* W-3. Transfer Learning
  1. Understanding transfer learning: the concepts ([Video][c2-w3-v1])
  2. Coding transfer learning from the inception mode ([Video][c2-w3-v2])
  3. Coding your own model with transferred features ([Video][c2-w3-v3])
  4. Exploring dropouts ([Video][c2-w3-v4])
  5. Exploring Transfer Learning with Inception ([Video][c2-w3-v5])
* W-4. Multiclass Classifications
  1. Moving from binary to multi-class classification ([Video][c2-w4-v1])
  2. Explore multi-class with Rock Paper Scissors dataset ([Video][c2-w4-v2])
  3. Train a classifier with Rock Paper Scissors ([Video][c2-w4-v3])
  4. Test the Rock Paper Scissors classifier ([Video][c2-w4-v4])

[c2-w1-v1]: https://drive.google.com/file/d/1DWVtYgtQXy457gy98QuwfgwG4F4t-ZE5/view?usp=sharing
[c2-w1-v2]: https://drive.google.com/file/d/1DQWt955CboyiVBAFbg_6QGwGG5o-wx04/view?usp=sharing
[c2-w1-n2]: https://colab.research.google.com/drive/1tEQd1tJbYhu3cK89TBEVNAs3w6za-PDG
[c2-w1-v3]: https://drive.google.com/file/d/1DU6lV10hIDE5ieYneJfPKjZ7TbuQ7dRf/view?usp=sharing
[c2-w1-v4]: https://drive.google.com/file/d/1DTQl5w2ZSBfm0uCpq5AhbskZMANQYxKC/view?usp=sharing
[c2-w1-v5]: https://drive.google.com/file/d/1DRc7YxwoQsDy7s9kIROEyGTjDEVwqogs/view?usp=sharing
[c2-w1-kg]: https://www.kaggle.com/c/dogs-vs-cats
[c2-w1-e2]: https://
[c2-w2-v1]: https://drive.google.com/file/d/1DZdyxQVriDyTN6OPuLSx28Pr1O2W3XjG/view?usp=sharing
[c2-w2-v2]: https://drive.google.com/file/d/1DYYDrIo5Deaimjz92joXcUT7q-TCRAyK/view?usp=sharing
[c2-w2-v3]: https://drive.google.com/file/d/1DWeyjIBlXCTpc7I-MO1hcSInWqIC0uHX/view?usp=sharing
[c2-w2-v4]: https://drive.google.com/file/d/1DWgspoIdW4JRCVIFZoPEs0n9XJCrJrcc/view?usp=sharing
[c2-w2-v5]: https://drive.google.com/file/d/1D_FdXNNDkH_t3RJQLGtTDyXus4RAYowE/view?usp=sharing
[c2-w3-v1]: https://drive.google.com/file/d/1Di947KFrYxiYT-YUEy9CZ87UytlqP9P7/view?usp=sharing
[c2-w3-v2]: https://drive.google.com/file/d/1DhHtl0Ir6jnjEIS6Jk9dGXCmUD_oiSuN/view?usp=sharing
[c2-w3-v3]: https://drive.google.com/file/d/1DgpXhU2GjLwsKrUIRifFI2_-QSbC7M_Z/view?usp=sharing
[c2-w3-v4]: https://drive.google.com/file/d/1D_ypCs5orl_i_8qt5V6kmnzOlfvJ3LDr/view?usp=sharing
[c2-w3-v5]: https://drive.google.com/file/d/1Dcj_81RSUFJI24fiZWvzuMmCDON3o2-L/view?usp=sharing
[c2-w4-v1]: https://drive.google.com/file/d/1Do5Cn1od15LWT17f9el8GRXyu5-Thgb1/view?usp=sharing
[c2-w4-v2]: https://drive.google.com/file/d/1Dn7X1ODEj34EMVGwBs9eQsMmbBYI3A-c/view?usp=sharing
[c2-w4-v3]: https://drive.google.com/file/d/1DkdxDDfrCTQVBW59GyzVMM4-3jJ5z4OW/view?usp=sharing
[c2-w4-v4]: https://drive.google.com/file/d/1DsmPadngXe71NXFBxVh2FQhXpfstDfKo/view?usp=sharing


## Class 3. 텐서플로우에서 자연어 처리 (NLP)
* W-1. 문장에서 Sentiment
  1. 서론 ([Video][c3-w1-v1])
  2. 단어의 encoding ([Video][c3-w1-v2])
  3. API 사용 ([Video][c3-w1-v3])
     노트북 예제
  4. Text to sequence ([Video][c3-w1-v4]) 
  5. Looking more at the Tokenizer ([Video][c3-w1-v5])
  6. Padding ([Video][c3-w1-v6])
  7. Notebook for lesson ([Video][c3-w1-v7])
  8. Sarcasm, really? ([Video][c3-w1-v8])
  9. Working with the Tokenizer ([Video][c3-w1-v9])
  10. Sarcasm 실습 ([Video][c3-w1-v10])
     News headlines dataset for sarcasm detection
* W-2. Word Embeddings
  1. 서론 ([Video][c3-w2-v1])
  2. IMBD dataset ([Video][c3-w2-v2])
  3. Looking into the details
  4. How can we use vectors?
  5. More into the details
  6. Notebook for lesson 
  7. Remember the sarcasm dataset?
  8. Building a classifier for the sarcasm dataset
  9. Let’s talk about the loss function
  10. Pre-tokenized datasets
* W-3. Sequence 모델
  1. 서론 ([Video]())
  2. LSTM ([Video]())
  3. LSTM 구현 ([Video]())
  4. Accuracy와 loss ([Video]())
  5. A word from Laurence
  6. Looking into the code
  7. Using a convolutional network
      Going back to the IMDB dataset
      Tips from Laurence
* W-4. Sequence 모델과 문학
  1. 서론 ([Video]())
  2. Looking into the code 
  3. Training the data
  4. More on training the data
  5. 노트북 예제 ([Video]())
  6. Finding what the next word should be
      Example
      Predicting a word
      Poetry!
      Looking into the code
      Laurence the poet!
      Your next task

[c3-w1-v1]: https://drive.google.com/file/d/1DtjmzeQSGvdonXb_qZAnMn7IKLZPvA7O/view?usp=sharing
[c3-w1-v2]: https://drive.google.com/file/d/1DtMEqPVrDKXy9inU86zeC3ReyY2lQCD3/view?usp=sharing
[c3-w1-v3]: https://drive.google.com/file/d/1DuLOXNBxD3Bh5a9U70rpNUzysqylJ-6a/view?usp=sharing
[c3-w1-v4]: https://drive.google.com/file/d/1DtIeEAVlY0Irrl_yxpS_FvnyiJY5kXHq/view?usp=sharing
[c3-w1-v5]: https://drive.google.com/file/d/1DxYnYXXXPKRgQ6ecL-l7HNF-Lxo4AGiw/view?usp=sharing
[c3-w1-v6]: https://drive.google.com/file/d/1DywRr2rVEMqK-OqRfACTo2ca3x2AtXIY/view?usp=sharing
[c3-w1-v7]: https://drive.google.com/file/d/1CL4Exwel-BYtuT8nnXLVxnQu-o8ljEW8/view?usp=sharing
[c3-w1-v8]: https://drive.google.com/file/d/1C_sKk0sUMl_cDYa96u2-RQy3Ge2Cz3RN/view?usp=sharing
[c3-w1-v9]: https://drive.google.com/file/d/1CcHLyT_CLzuOnBxMUcsIN1us3lt-kq5G/view?usp=sharing
[c3-w1-v10]: https://drive.google.com/file/d/1Co8nSIuYNw7Igw5QBG2WCgalG44c11ZP/view?usp=sharing
[c3-w2-v1]: https://drive.google.com/file/d/1CvlgIdwgb85VfHdc7COqSZfzR7cT75Fy/view?usp=sharing
[c3=w2-v2]: https://drive.google.com/file/d/1D6KW_myjoPyAt88f_1UhasT6sguK45h2/view?usp=sharing


## Class 4. Sequences, Time Series & Prediction
* W-1. Sequence와 예측
  1. Time series의 예 ([Video][c4-w1-v1])
  2. Time series에 적용한 머신러닝 ([Video][c4-w1-v2])
  3. Time series에서 패턴 ([Video][c4-w1-v3])
  4. Time series 서론 ([Video][c4-w1-v4], [Notebook][c4-w1-n4])
  5. Train, validation and test sets ([Video][c4-w1-v5])
  6. 성능 평가를 위한 Metrics ([Video][c4-w1-v6])
  7. Moving average and differencing
  8. Trailing versus centered windows
  9. Forecasting
* W-2. Deep Neural Networks for Time Series
  1. Preparing features and labels
  2. Preparing features and labels
  3. Feeding windowed dataset into neural network
  4. Single layer neural network
  5. Machine learning on time windows
  6. Prediction
  7. More on single layer neural network
  8. Deep neural network training, tuning and prediction
  9. Deep neural network
* W-3. Time Series를 위한 RNN
  1. 개념 정리 ([Video]())
  2. Shape of the inputs to the RNN
  3. Outputting a sequence
  4. Lambda layers
  5. Adjusting the learning rate dynamically
  6. RNN
  7. LSTM
  8. LSTM 코딩 ([Video]())
  9. More on LSTM
* W-4. 실생활의 time series data
  1. Convolutions
  2. 양방향 LSTM ([Video]())
  3. LSTM
  4. Real data - sunspots
  5. Train and tune the model
  6. Prediction
  7. Sunspots
  8. Combining our tools for analysis
  9. Congratulations!

[c4-w1-v1]: https://drive.google.com/file/d/1HC7fU4slqoRZX_ZmoR4Corrm5fiYxg1H/view?usp=sharing
[c4-w1-v2]: https://drive.google.com/file/d/1HItIETh64XY6AqCcYpn8386ayUEFPeHy/view?usp=sharing
[c4-w1-v3]: https://drive.google.com/file/d/1H6vVcZlvOKf-rCTg-34r8vxrZ85ryYO5/view?usp=sharing
[c4-w1-v4]: https://drive.google.com/file/d/1H11O5P6JPvyTP-XIZ-docZhq5PljGyZC/view?usp=sharing
[c4-w1-n4]: https://colab.research.google.com/drive/1O2LH56mUmh5U1rJuHTBx5VYUuqbSiJAT
[c4-w1-v5]: https://drive.google.com/file/d/1HRjc72wdq9DAR5FVQCiHVLi8e8q1JOA0/view?usp=sharing
[c4-w1-v6]: https://drive.google.com/file/d/1Hta2rptk3XPu0fNGWIRLJgrv2SIYXhaT/view?usp=sharing
